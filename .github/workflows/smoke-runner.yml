name: smoke / run-uaengine

on:
  push:
  pull_request:

permissions:
  contents: read

env:
  UENG_CACHE_ROOT: ${{ github.workspace }}/.cache

jobs:
  # ------------------------------------------------------------
  # Build & run --version on all OSes using your runner scripts
  # (Linux/macOS: Ninja + ccache)  (Windows: MSBuild)
  # ------------------------------------------------------------
  smoke-run:
    name: smoke (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # ---------- Linux/macOS: Ninja + ccache ----------
      - name: Install Ninja & ccache (Linux)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y ninja-build ccache

      - name: Install Ninja & ccache (macOS)
        if: runner.os == 'macOS'
        run: |
          brew update
          brew install ninja ccache || true

      - name: Prepare ccache directory (Unix)
        if: runner.os != 'Windows'
        run: |
          mkdir -p "${UENG_CACHE_ROOT}/ccache"

      - name: Restore ccache (Unix)
        if: runner.os != 'Windows'
        uses: actions/cache@v4
        with:
          path: ${{ env.UENG_CACHE_ROOT }}/ccache
          key: ccache-${{ runner.os }}-${{ hashFiles('CMakeLists.txt', 'src/**', 'include/**', 'snippets/**', 'cmake/**') }}
          restore-keys: |
            ccache-${{ runner.os }}-

      - name: Configure + Build (Unix / Ninja + ccache)
        if: runner.os != 'Windows'
        shell: bash
        env:
          CCACHE_DIR: ${{ env.UENG_CACHE_ROOT }}/ccache
        run: |
          cmake -S . -B build-ninja \
            -G Ninja -DCMAKE_BUILD_TYPE=Release \
            -DCMAKE_C_COMPILER_LAUNCHER=ccache \
            -DCMAKE_CXX_COMPILER_LAUNCHER=ccache
          cmake --build build-ninja -j
          ccache -s || true

      - name: Cache build folder (Unix; best-effort)
        if: runner.os != 'Windows'
        uses: actions/cache@v4
        with:
          path: build-ninja
          key: cmake-build-${{ runner.os }}-${{ github.ref }}-${{ hashFiles('CMakeLists.txt', 'src/**', 'include/**', 'snippets/**', 'cmake/**') }}
          restore-keys: |
            cmake-build-${{ runner.os }}-${{ github.ref }}-
            cmake-build-${{ runner.os }}-

      # ---------- Windows: MSBuild (baseline path) ----------
      - name: Configure + Build (Windows / MSBuild)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          cmake -S . -B build
          cmake --build build -j

      - name: Cache build folder (Windows; best-effort)
        if: runner.os == 'Windows'
        uses: actions/cache@v4
        with:
          path: build
          key: cmake-build-${{ runner.os }}-${{ github.ref }}-${{ hashFiles('CMakeLists.txt', 'src/**', 'include/**', 'snippets/**', 'cmake/**') }}
          restore-keys: |
            cmake-build-${{ runner.os }}-${{ github.ref }}-
            cmake-build-${{ runner.os }}-

      # ---------- Exercise runner scripts ----------
      - name: Run (Windows) — --version
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $env:UENG_RUN_VERBOSE="1"
          powershell -ExecutionPolicy Bypass -File scripts\run-uaengine.ps1 -- --version

      - name: Run (Unix) — --version
        if: runner.os != 'Windows'
        shell: bash
        run: |
          export UENG_RUN_VERBOSE=1
          scripts/run-uaengine.sh -- --version

  # ------------------------------------------------------------
  # NEW: Windows Ninja + sccache path (fast build on Windows)
  # ------------------------------------------------------------
  smoke-run-win-ninja-sccache:
    name: smoke (windows-ninja-sccache)
    runs-on: windows-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Ninja + sccache (Chocolatey)
        shell: pwsh
        run: |
          choco install ninja -y --no-progress
          choco install sccache -y --no-progress

      - name: Prepare sccache dir
        shell: pwsh
        run: |
          $cache = Join-Path $env:GITHUB_WORKSPACE ".cache\sccache"
          New-Item -ItemType Directory -Force -Path $cache | Out-Null
          echo "SCCACHE_DIR=$cache" >> $env:GITHUB_ENV
          echo "SCCACHE_CACHE_SIZE=2G" >> $env:GITHUB_ENV

      - name: Restore sccache
        uses: actions/cache@v4
        with:
          path: ${{ env.SCCACHE_DIR }}
          key: sccache-win-${{ hashFiles('CMakeLists.txt', 'src/**', 'include/**', 'snippets/**', 'cmake/**') }}
          restore-keys: |
            sccache-win-

      - name: Configure + Build (Ninja + sccache)
        shell: pwsh
        run: |
          cmake -S . -B build-ninja -G Ninja `
            -DCMAKE_BUILD_TYPE=Release `
            -DCMAKE_C_COMPILER_LAUNCHER=sccache `
            -DCMAKE_CXX_COMPILER_LAUNCHER=sccache
          cmake --build build-ninja -j
          sccache --show-stats || $true

      - name: Run — --version via runner
        shell: pwsh
        run: |
          $env:UENG_RUN_VERBOSE="1"
          powershell -ExecutionPolicy Bypass -File scripts\run-uaengine.ps1 -- --version

  # ------------------------------------------------------------------
  # Optional: OpenAI smoke (Linux + Windows Ninja/sccache).
  # Runs only if OPENAI_API_KEY is present.
  # ------------------------------------------------------------------
  smoke-run-openai-linux:
    if: ${{ secrets.OPENAI_API_KEY != '' }}
    name: smoke-openai (linux)
    runs-on: ubuntu-latest
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      UENG_LLM_PROVIDER: openai
      UENG_CACHE_ROOT: ${{ github.workspace }}/.cache

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Ninja & ccache
        run: |
          sudo apt-get update
          sudo apt-get install -y ninja-build ccache

      - name: Prepare ccache
        run: mkdir -p "${UENG_CACHE_ROOT}/ccache"

      - name: Restore ccache
        uses: actions/cache@v4
        with:
          path: ${{ env.UENG_CACHE_ROOT }}/ccache
          key: ccache-openai-linux-${{ hashFiles('CMakeLists.txt', 'src/**', 'include/**', 'snippets/**', 'cmake/**') }}
          restore-keys: |
            ccache-openai-linux-

      - name: Configure + Build (Ninja + OpenAI)
        env:
          CCACHE_DIR: ${{ env.UENG_CACHE_ROOT }}/ccache
        run: |
          cmake -S . -B build-ninja -G Ninja -DCMAKE_BUILD_TYPE=Release \
                -DUAENG_ENABLE_OPENAI=ON \
                -DCMAKE_C_COMPILER_LAUNCHER=ccache \
                -DCMAKE_CXX_COMPILER_LAUNCHER=ccache
          cmake --build build-ninja -j
          ccache -s || true

      - name: Run — llm-selftest (OpenAI)
        run: scripts/run-uaengine.sh llm-selftest gpt-4o-mini

  smoke-run-openai-win-ninja-sccache:
    if: ${{ secrets.OPENAI_API_KEY != '' }}
    name: smoke-openai (windows-ninja-sccache)
    runs-on: windows-latest
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      UENG_LLM_PROVIDER: openai

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Ninja + sccache
        shell: pwsh
        run: |
          choco install ninja -y --no-progress
          choco install sccache -y --no-progress

      - name: Prepare sccache dir
        shell: pwsh
        run: |
          $cache = Join-Path $env:GITHUB_WORKSPACE ".cache\sccache"
          New-Item -ItemType Directory -Force -Path $cache | Out-Null
          echo "SCCACHE_DIR=$cache" >> $env:GITHUB_ENV
          echo "SCCACHE_CACHE_SIZE=2G" >> $env:GITHUB_ENV

      - name: Restore sccache
        uses: actions/cache@v4
        with:
          path: ${{ env.SCCACHE_DIR }}
          key: sccache-win-openai-${{ hashFiles('CMakeLists.txt', 'src/**', 'include/**', 'snippets/**', 'cmake/**') }}
          restore-keys: |
            sccache-win-openai-

      - name: Configure + Build (Ninja + sccache + OpenAI)
        shell: pwsh
        run: |
          cmake -S . -B build-ninja -G Ninja `
            -DCMAKE_BUILD_TYPE=Release `
            -DUAENG_ENABLE_OPENAI=ON `
            -DCMAKE_C_COMPILER_LAUNCHER=sccache `
            -DCMAKE_CXX_COMPILER_LAUNCHER=sccache
          cmake --build build-ninja -j
          sccache --show-stats || $true

      - name: Run — llm-selftest (OpenAI)
        shell: pwsh
        run: |
          powershell -ExecutionPolicy Bypass -File scripts\run-uaengine.ps1 -- llm-selftest gpt-4o-mini

  # ------------------------------------------------------------------
  # Optional: Ollama smoke (Docker) with cached model
  # Enable via repo variable: UENG_ENABLE_OLLAMA_SMOKE=true
  # ------------------------------------------------------------------
  smoke-run-ollama:
    if: ${{ vars.UENG_ENABLE_OLLAMA_SMOKE == 'true' }}
    name: smoke-ollama (ubuntu)
    runs-on: ubuntu-latest
    env:
      UENG_LLM_PROVIDER: ollama
      UENG_OLLAMA_HOST: http://localhost:11434
      OLLAMA_CACHE_DIR: ${{ github.workspace }}/.cache/ollama-models

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Ninja & tools
        run: |
          sudo apt-get update
          sudo apt-get install -y ninja-build jq curl

      - name: Prepare model cache dir
        run: mkdir -p "${OLLAMA_CACHE_DIR}"

      - name: Restore Ollama model cache
        uses: actions/cache@v4
        with:
          path: ${{ env.OLLAMA_CACHE_DIR }}
          key: ollama-models-tinyllama
          restore-keys: ollama-models-

      - name: Start Ollama (Docker with model bind-mount)
        run: |
          docker run -d --name ollama -p 11434:11434 \
            -v "${OLLAMA_CACHE_DIR}:/root/.ollama" \
            ollama/ollama:latest
          for i in {1..60}; do
            if curl -fsS http://localhost:11434/api/tags >/dev/null; then
              echo "Ollama is up"; break
            fi
            echo "Waiting for Ollama... ($i)"; sleep 2
          done

      - name: Pull tiny model (cached)
        run: docker exec ollama ollama pull tinyllama

      - name: Configure + Build (Ninja + OLLAMA)
        run: |
          cmake -S . -B build-ninja -G Ninja -DCMAKE_BUILD_TYPE=Release -DUAENG_ENABLE_OLLAMA=ON
          cmake --build build-ninja -j

      - name: Run — llm-selftest (Ollama)
        shell: bash
        run: |
          export UENG_RUN_VERBOSE=1
          scripts/run-uaengine.sh llm-selftest tinyllama

      - name: Docker logs (on failure)
        if: failure()
        run: docker logs ollama || true

      - name: Save Ollama model cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: ${{ env.OLLAMA_CACHE_DIR }}
          key: ollama-models-tinyllama

      - name: Cleanup Docker
        if: always()
        run: docker rm -f ollama || true
